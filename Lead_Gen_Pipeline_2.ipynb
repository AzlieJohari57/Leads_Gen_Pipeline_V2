{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f1d1a2",
   "metadata": {},
   "source": [
    "### Data Mining in RecordOwl (Silver 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b601322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import time\n",
    "import scrapy\n",
    "from scrapy_playwright.page import PageMethod\n",
    "from bs4 import BeautifulSoup\n",
    "import nest_asyncio\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re\n",
    "from apify_client import ApifyClient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c77d5d",
   "metadata": {},
   "source": [
    "### Ingesting from previous layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86bf8e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 500 rows from ./Staging/Bronze/bronze_data_1.parquet\n",
      "(500, 14)\n"
     ]
    }
   ],
   "source": [
    "parquet_path = \"./Staging/Bronze/bronze_data_1.parquet\"\n",
    "if os.path.exists(parquet_path):\n",
    "    acra_data_filtered_by_industry = pd.read_parquet(parquet_path, engine=\"fastparquet\")\n",
    "    print(f\"Loaded {len(acra_data_filtered_by_industry)} rows from {parquet_path}\")\n",
    "    print(acra_data_filtered_by_industry.shape)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Parquet file not found at {parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6348882",
   "metadata": {},
   "outputs": [],
   "source": [
    "acra_data_filtered_by_industry = acra_data_filtered_by_industry.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83b183e",
   "metadata": {},
   "source": [
    "### Mining RecordOwl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f852275e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting scraper - 50 UENs in 1 batches\n",
      "\n",
      "Batch 1/1 - 50 UENs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> 2025-12-04T14:53:31.600Z ACTOR: Pulling container image of build g6G5r98rF5fM6ecm3 from registry.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> 2025-12-04T14:53:31.602Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> 2025-12-04T14:53:31.637Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> 2025-12-04T14:53:31.848Z Will run command: xvfb-run -a -s \"-ac -screen 0 1920x1080x24+32 -nolisten tcp\" /bin/sh -c ./start_xvfb_and_run_cmd.sh && npm run start:prod --silent\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> 2025-12-04T14:53:33.386Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.4.4\",\"apifyClientVersion\":\"2.16.0\",\"crawleeVersion\":\"3.14.1\",\"osType\":\"Linux\",\"nodeVersion\":\"v22.19.0\"}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> 2025-12-04T14:53:33.505Z \u001b[32mINFO\u001b[39m  Configuring Puppeteer Scraper.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> 2025-12-04T14:53:34.493Z \u001b[32mINFO\u001b[39m  Configuration completed. Starting the scrape.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 1/50 pages, 0 failed requests, desired concurrency 2.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 3/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 5/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 7/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 9/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> 2025-12-04T14:53:34.637Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> 2025-12-04T14:54:34.637Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:Statistics:\u001b[39m PuppeteerCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":5940,\"requestsFinishedPerMinute\":11,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":65343,\"requestsTotal\":11,\"crawlerRuntimeMillis\":60239,\"retryHistogram\":[11]}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 11/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 13/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 14/50 pages, 0 failed requests, desired concurrency 2.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 16/50 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 18/50 pages, 0 failed requests, desired concurrency 2.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 20/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> 2025-12-04T14:54:34.693Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":1,\"desiredConcurrency\":1,\"systemStatus\":{\"isSystemIdle\":false,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0.039},\"cpuInfo\":{\"isOverloaded\":true,\"limitRatio\":0.4,\"actualRatio\":0.414},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> 2025-12-04T14:55:34.637Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:Statistics:\u001b[39m PuppeteerCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":6968,\"requestsFinishedPerMinute\":11,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":153301,\"requestsTotal\":22,\"crawlerRuntimeMillis\":120239,\"retryHistogram\":[22]}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 23/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 24/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 26/50 pages, 0 failed requests, desired concurrency 2.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 28/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 29/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 31/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> 2025-12-04T14:55:34.889Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":1,\"desiredConcurrency\":1,\"systemStatus\":{\"isSystemIdle\":false,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0},\"cpuInfo\":{\"isOverloaded\":true,\"limitRatio\":0.4,\"actualRatio\":0.531},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> 2025-12-04T14:56:34.681Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:Statistics:\u001b[39m PuppeteerCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":6817,\"requestsFinishedPerMinute\":11,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":218133,\"requestsTotal\":32,\"crawlerRuntimeMillis\":180283,\"retryHistogram\":[32]}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 32/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 34/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 36/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 37/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 39/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 40/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> 2025-12-04T14:56:34.903Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":1,\"desiredConcurrency\":1,\"systemStatus\":{\"isSystemIdle\":false,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0.058},\"cpuInfo\":{\"isOverloaded\":true,\"limitRatio\":0.4,\"actualRatio\":0.679},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> 2025-12-04T14:57:34.682Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:Statistics:\u001b[39m PuppeteerCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":6645,\"requestsFinishedPerMinute\":10,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":279108,\"requestsTotal\":42,\"crawlerRuntimeMillis\":240284,\"retryHistogram\":[42]}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 42/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 44/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 46/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 47/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Crawled 49/50 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> 2025-12-04T14:57:34.907Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":1,\"desiredConcurrency\":1,\"systemStatus\":{\"isSystemIdle\":false,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0.039},\"cpuInfo\":{\"isOverloaded\":true,\"limitRatio\":0.4,\"actualRatio\":0.728},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> 2025-12-04T14:58:17.279Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m All requests from the queue have been processed, the crawler will shut down.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> 2025-12-04T14:58:18.022Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Final request statistics:\u001b[90m {\"requestsFinished\":50,\"requestsFailed\":0,\"retryHistogram\":[50],\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":6416,\"requestsFinishedPerMinute\":11,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":320790,\"requestsTotal\":50,\"crawlerRuntimeMillis\":283624}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> 2025-12-04T14:58:18.024Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Finished! Total 50 requests: 50 succeeded, 0 failed.\u001b[90m {\"terminal\":true}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> Status: RUNNING, Message: Finished! Total 50 requests: 50 succeeded, 0 failed.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:ALKN0wQb4tGRZf27T]\u001b[0m -> 2025-12-04T14:58:18.035Z \u001b[32mINFO\u001b[39m  Puppeteer Scraper finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Success: 50/50\n"
     ]
    }
   ],
   "source": [
    "# COST-OPTIMIZED SCRAPER - V10 FIXED (No waitForTimeout)\n",
    "from apify_client import ApifyClient\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "client = ApifyClient(\"apify_api_OTOzi23olTLbw5NkxeilppwjsaoRHL3zrxRk\")\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "MAX_CONCURRENCY = 3\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "def create_pagefunction_v9_fixed() -> str:\n",
    "    \"\"\"V9: Fixed - removed waitForTimeout, using proper Puppeteer methods\"\"\"\n",
    "    return \"\"\"\n",
    "async function pageFunction(context) {\n",
    "    const { page, log, request } = context;\n",
    "    const uen = request?.userData?.uen || '';\n",
    "\n",
    "    if (!uen) return { status: 'error', uen: null, error: 'Missing UEN' };\n",
    "\n",
    "    try {\n",
    "        // Wait for search results with fallback\n",
    "        try {\n",
    "            await page.waitForSelector('.flex-1.min-w-0', { timeout: 20000 });\n",
    "        } catch (e) {\n",
    "            await page.waitForSelector('a[href*=\"/company/\"]', { timeout: 10000 });\n",
    "        }\n",
    "\n",
    "        // Find and click link with EXACT UEN match\n",
    "        const linkClickResult = await page.evaluate((targetUen) => {\n",
    "            const uenUpper = targetUen.toUpperCase();\n",
    "            const allLinks = document.querySelectorAll('a[href*=\"/company/\"]');\n",
    "\n",
    "            if (allLinks.length === 0) {\n",
    "                return { clicked: false, reason: 'No company links found' };\n",
    "            }\n",
    "\n",
    "            // First pass: EXACT UEN match\n",
    "            for (const link of allLinks) {\n",
    "                let parent = link.parentElement;\n",
    "                for (let i = 0; i < 5 && parent; i++) {\n",
    "                    const parentText = (parent.innerText || parent.textContent || '').toUpperCase();\n",
    "                    const uenPattern = new RegExp('\\\\\\\\b' + uenUpper.replace(/[.*+?^${}()|[\\\\\\\\]\\\\\\\\]/g, '\\\\\\\\$&') + '\\\\\\\\b');\n",
    "                    \n",
    "                    if (uenPattern.test(parentText)) {\n",
    "                        link.click();\n",
    "                        return { clicked: true, href: link.getAttribute('href'), matchType: 'exact' };\n",
    "                    }\n",
    "                    parent = parent.parentElement;\n",
    "                }\n",
    "            }\n",
    "\n",
    "            // Fallback: Click first result\n",
    "            allLinks[0].click();\n",
    "            return { clicked: true, href: allLinks[0].getAttribute('href'), matchType: 'fallback' };\n",
    "        }, uen);\n",
    "\n",
    "        if (!linkClickResult.clicked) {\n",
    "            return { status: 'not_found', uen, error: linkClickResult.reason || 'No search results' };\n",
    "        }\n",
    "\n",
    "        // Wait for navigation\n",
    "        try {\n",
    "            await page.waitForNavigation({ waitUntil: 'domcontentloaded', timeout: 25000 });\n",
    "        } catch (navError) {\n",
    "            const currentUrl = page.url();\n",
    "            if (!currentUrl.includes('/company/')) {\n",
    "                return { status: 'error', uen, error: 'Navigation failed' };\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Wait for content with multiple fallback selectors\n",
    "        try {\n",
    "            await page.waitForSelector('dt', { timeout: 15000 });\n",
    "        } catch (e1) {\n",
    "            try {\n",
    "                await page.waitForSelector('dd', { timeout: 10000 });\n",
    "            } catch (e2) {\n",
    "                try {\n",
    "                    await page.waitForSelector('a[href^=\"mailto:\"]', { timeout: 5000 });\n",
    "                } catch (e3) {\n",
    "                    // Continue anyway - some pages might not have these elements\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Verify UEN on the company page\n",
    "        const uenVerification = await page.evaluate((targetUen) => {\n",
    "            const uenUpper = targetUen.toUpperCase();\n",
    "            const pageText = (document.body.innerText || document.body.textContent || '').toUpperCase();\n",
    "            const uenPattern = new RegExp('\\\\\\\\b' + uenUpper.replace(/[.*+?^${}()|[\\\\\\\\]\\\\\\\\]/g, '\\\\\\\\$&') + '\\\\\\\\b');\n",
    "            \n",
    "            let uenFound = uenPattern.test(pageText);\n",
    "            let uenInStructure = false;\n",
    "            \n",
    "            document.querySelectorAll('dt').forEach(dt => {\n",
    "                const dtText = dt.textContent.toLowerCase().trim();\n",
    "                if (dtText.includes('uen') || dtText.includes('registration') || dtText.includes('business registration')) {\n",
    "                    const dd = dt.nextElementSibling;\n",
    "                    if (dd && dd.tagName === 'DD') {\n",
    "                        const ddText = dd.textContent.toUpperCase().trim();\n",
    "                        if (uenPattern.test(ddText)) {\n",
    "                            uenInStructure = true;\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            });\n",
    "\n",
    "            return {\n",
    "                uenFoundInPage: uenFound || uenInStructure,\n",
    "                pageUrl: window.location.href\n",
    "            };\n",
    "        }, uen);\n",
    "\n",
    "        // If UEN not found, return mismatch\n",
    "        if (!uenVerification.uenFoundInPage) {\n",
    "            return {\n",
    "                status: 'uen_mismatch',\n",
    "                uen,\n",
    "                url: uenVerification.pageUrl,\n",
    "                error: 'UEN not found on company page'\n",
    "            };\n",
    "        }\n",
    "\n",
    "        // Extract data\n",
    "        const data = await page.evaluate(() => {\n",
    "            const SOCIAL_MEDIA_DOMAINS = ['facebook.com','linkedin.com','instagram.com','tiktok.com','twitter.com','x.com','youtube.com','pinterest.com'];\n",
    "            \n",
    "            // EMAIL\n",
    "            const emails = [];\n",
    "            document.querySelectorAll('a[href^=\"mailto:\"]').forEach(a => {\n",
    "                const email = a.href.replace('mailto:', '').trim();\n",
    "                if (email && email.includes('@') && !emails.includes(email)) {\n",
    "                    emails.push(email);\n",
    "                }\n",
    "            });\n",
    "            \n",
    "            // PHONE\n",
    "            const phones = [];\n",
    "            \n",
    "            function formatSingaporePhone(text) {\n",
    "                const digitsOnly = text.replace(/\\\\D/g, '');\n",
    "                if (digitsOnly.length === 8) return '+65' + digitsOnly;\n",
    "                if (digitsOnly.length === 10 && digitsOnly.startsWith('65')) return '+' + digitsOnly;\n",
    "                if (digitsOnly.length === 11 && digitsOnly.startsWith('65')) return '+65' + digitsOnly.slice(2);\n",
    "                if (digitsOnly.length >= 10) {\n",
    "                    for (let i = 0; i <= digitsOnly.length - 10; i++) {\n",
    "                        if (digitsOnly.slice(i, i+2) === '65' && digitsOnly.length - i >= 10) {\n",
    "                            return '+' + digitsOnly.slice(i, i+10);\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "                return null;\n",
    "            }\n",
    "            \n",
    "            // tel: links\n",
    "            document.querySelectorAll('a[href^=\"tel:\"]').forEach(a => {\n",
    "                const formatted = formatSingaporePhone(a.href.replace('tel:', '').trim());\n",
    "                if (formatted && !phones.includes(formatted)) phones.push(formatted);\n",
    "            });\n",
    "            \n",
    "            // dt/dd structure\n",
    "            const phoneKeywords = ['company contact', 'business contact', 'office phone', 'main phone', 'business phone', 'company phone', 'contact number', 'phone', 'tel', 'mobile', 'call', 'contact no'];\n",
    "            document.querySelectorAll('dt').forEach(dt => {\n",
    "                const dtText = dt.textContent.toLowerCase().trim();\n",
    "                if (phoneKeywords.some(kw => dtText.includes(kw))) {\n",
    "                    const dd = dt.nextElementSibling;\n",
    "                    if (dd && dd.tagName === 'DD') {\n",
    "                        const formatted = formatSingaporePhone(dd.textContent.trim());\n",
    "                        if (formatted && !phones.includes(formatted)) phones.push(formatted);\n",
    "                    }\n",
    "                }\n",
    "            });\n",
    "            \n",
    "            // Pattern matching\n",
    "            const bodyText = document.body.innerText || document.body.textContent;\n",
    "            const phonePatterns = [\n",
    "                /\\\\b(\\\\+65[\\\\s\\\\-]?)?([689]\\\\d{3}[\\\\s\\\\-]?\\\\d{4})\\\\b/g,\n",
    "                /\\\\b65[\\\\s\\\\-]?([689]\\\\d{3})[\\\\s\\\\-]?(\\\\d{4})\\\\b/g,\n",
    "                /\\\\b([689]\\\\d{3})[\\\\s\\\\-](\\\\d{4})\\\\b/g\n",
    "            ];\n",
    "            phonePatterns.forEach(pattern => {\n",
    "                const matches = bodyText.matchAll(pattern);\n",
    "                for (const match of matches) {\n",
    "                    const formatted = formatSingaporePhone(match[0]);\n",
    "                    if (formatted && !phones.includes(formatted)) phones.push(formatted);\n",
    "                }\n",
    "            });\n",
    "            \n",
    "            // WEBSITE\n",
    "            const websites = [];\n",
    "            document.querySelectorAll('a[href^=\"http\"]').forEach(a => {\n",
    "                const href = a.href.trim().toLowerCase();\n",
    "                if (!SOCIAL_MEDIA_DOMAINS.some(d => href.includes(d)) && !href.includes('recordowl') && !href.includes('apify')) {\n",
    "                    if (href.match(/\\\\.(com|sg|net|org|co)/)) websites.push(a.href);\n",
    "                }\n",
    "            });\n",
    "            \n",
    "            // SOCIAL MEDIA\n",
    "            const facebook = [], linkedin = [], instagram = [], tiktok = [];\n",
    "            document.querySelectorAll('a[href*=\"facebook.com\"]').forEach(a => { if (!facebook.includes(a.href)) facebook.push(a.href); });\n",
    "            document.querySelectorAll('a[href*=\"linkedin.com\"]').forEach(a => { if (!linkedin.includes(a.href)) linkedin.push(a.href); });\n",
    "            document.querySelectorAll('a[href*=\"instagram.com\"]').forEach(a => { if (!instagram.includes(a.href)) instagram.push(a.href); });\n",
    "            document.querySelectorAll('a[href*=\"tiktok.com\"]').forEach(a => { if (!tiktok.includes(a.href)) tiktok.push(a.href); });\n",
    "            \n",
    "            // ADDRESS\n",
    "            let address = null;\n",
    "            const addressLabels = ['registered address', 'registered office address', 'address', 'principal place of business'];\n",
    "            document.querySelectorAll('dt').forEach(dt => {\n",
    "                const dtText = dt.textContent.toLowerCase().trim();\n",
    "                if (addressLabels.some(label => dtText.includes(label))) {\n",
    "                    const dd = dt.nextElementSibling;\n",
    "                    if (dd && dd.tagName === 'DD') address = dd.textContent.trim();\n",
    "                }\n",
    "            });\n",
    "\n",
    "            return {\n",
    "                emails: emails.length ? emails : null,\n",
    "                phones: phones.length ? phones : null,\n",
    "                website: websites.length ? websites[0] : null,\n",
    "                facebook: facebook.length ? facebook : null,\n",
    "                linkedin: linkedin.length ? linkedin : null,\n",
    "                instagram: instagram.length ? instagram : null,\n",
    "                tiktok: tiktok.length ? tiktok : null,\n",
    "                address: address\n",
    "            };\n",
    "        });\n",
    "\n",
    "        return { status: 'success', uen, url: page.url(), ...data };\n",
    "\n",
    "    } catch (err) {\n",
    "        return { status: 'error', uen, error: err.message };\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def run_scraper(client, uens):\n",
    "    start_urls = [{\"url\": f\"https://recordowl.com/search?name={uen}\", \"userData\": {\"uen\": uen}} for uen in uens]\n",
    "\n",
    "    run_input = {\n",
    "    \"startUrls\": start_urls,\n",
    "    \"useChrome\": False,\n",
    "    \"headless\": True,\n",
    "    \"stealth\": False,  # CHANGED: Removed stealth overhead\n",
    "    \"pageFunction\": create_pagefunction_v9_fixed(),\n",
    "    \"maxRequestRetries\": MAX_RETRIES,\n",
    "    \"maxRequestsPerCrawl\": len(start_urls),\n",
    "    \"maxConcurrency\": MAX_CONCURRENCY,\n",
    "    \"memoryMbytes\": 2048,  # NEW: Reduced from 4096 MB\n",
    "    \"pageLoadTimeoutSecs\": 25,  # CHANGED: Reduced from 40\n",
    "    \"pageFunctionTimeoutSecs\": 60,  # CHANGED: Reduced from 120\n",
    "    \"waitUntil\": [\"domcontentloaded\"],\n",
    "    \"proxyConfiguration\": {\"useApifyProxy\": True},  # CHANGED: Datacenter instead of residential\n",
    "}\n",
    "\n",
    "    try:\n",
    "        run = client.actor(\"apify/puppeteer-scraper\").call(run_input=run_input)\n",
    "        if not run or not isinstance(run, dict) or 'id' not in run:\n",
    "            return [], \"API returned invalid response\"\n",
    "    except Exception as e:\n",
    "        return [], f\"API call failed: {str(e)}\"\n",
    "\n",
    "    try:\n",
    "        run_client = client.run(run[\"id\"])\n",
    "        run_info = run_client.wait_for_finish()\n",
    "        status = run_info.get('status', 'UNKNOWN')\n",
    "\n",
    "        if status in ['FAILED', 'TIMED-OUT', 'ABORTED']:\n",
    "            return [], f\"Actor run {status}\"\n",
    "\n",
    "        if status == \"SUCCEEDED\" and \"defaultDatasetId\" in run:\n",
    "            dataset = client.dataset(run[\"defaultDatasetId\"])\n",
    "            items = list(dataset.iterate_items())\n",
    "            return items, None\n",
    "\n",
    "        return [], f\"Scraping failed with status: {status}\"\n",
    "    except Exception as e:\n",
    "        return [], f\"Run monitoring error: {str(e)}\"\n",
    "\n",
    "\n",
    "# Execute scraper\n",
    "all_results = []\n",
    "total_rows = len(acra_data_filtered_by_industry)\n",
    "total_batches = (total_rows + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "\n",
    "print(f\"Starting scraper - {total_rows} UENs in {total_batches} batches\")\n",
    "\n",
    "for batch_idx in range(0, total_rows, BATCH_SIZE):\n",
    "    batch = acra_data_filtered_by_industry.iloc[batch_idx:batch_idx + BATCH_SIZE]\n",
    "    uens = [str(row['UEN']).strip() for _, row in batch.iterrows()]\n",
    "    \n",
    "    batch_num = (batch_idx//BATCH_SIZE)+1\n",
    "    print(f\"\\nBatch {batch_num}/{total_batches} - {len(uens)} UENs...\")\n",
    "    \n",
    "    items, error = run_scraper(client, uens)\n",
    "    \n",
    "    if error:\n",
    "        print(f\"  Error: {error}\")\n",
    "        for uen in uens:\n",
    "            all_results.append({\n",
    "                \"UEN\": uen, \"Status\": \"error\", \"Error\": error,\n",
    "                **{k: None for k in ['Emails','Phones','Website','Facebook','LinkedIn','Instagram','TikTok','address','RecordOwl_Link']}\n",
    "            })\n",
    "        continue\n",
    "    \n",
    "    uen_map = {item.get('uen'): item for item in items if item.get('uen')}\n",
    "    \n",
    "    success_count = 0\n",
    "    for uen in uens:\n",
    "        item = uen_map.get(uen)\n",
    "        if not item:\n",
    "            all_results.append({\n",
    "                \"UEN\": uen, \"Status\": \"missing\", \"Error\": \"No data returned\",\n",
    "                **{k: None for k in ['Emails','Phones','Website','Facebook','LinkedIn','Instagram','TikTok','address','RecordOwl_Link']}\n",
    "            })\n",
    "        else:\n",
    "            status = item.get('status', 'error')\n",
    "            if status == 'success':\n",
    "                success_count += 1\n",
    "            \n",
    "            all_results.append({\n",
    "                'UEN': uen,\n",
    "                'Status': status,\n",
    "                'Error': item.get('error'),\n",
    "                'Emails': item.get('emails'),\n",
    "                'Phones': item.get('phones'),\n",
    "                'Website': item.get('website'),\n",
    "                'Facebook': item.get('facebook'),\n",
    "                'LinkedIn': item.get('linkedin'),\n",
    "                'Instagram': item.get('instagram'),\n",
    "                'TikTok': item.get('tiktok'),\n",
    "                'address': item.get('address'),\n",
    "                'RecordOwl_Link': item.get('url')\n",
    "            })\n",
    "    \n",
    "    print(f\"  Success: {success_count}/{len(uens)}\")\n",
    "    \n",
    "    if batch_num < total_batches:\n",
    "        time.sleep(3)\n",
    "\n",
    "New_Fresh_Leads = pd.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8b7e57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚úÖ SCRAPING COMPLETE\n",
      "======================================================================\n",
      "üìä Results Summary:\n",
      "   ‚Ä¢ Total processed: 50\n",
      "   ‚Ä¢ Successful: 50\n",
      "   ‚Ä¢ Failed: 0\n",
      "   ‚Ä¢ Missing: 0\n",
      "\n",
      "üìû Data Extracted:\n",
      "   ‚Ä¢ Phones: 23\n",
      "   ‚Ä¢ Emails: 19\n",
      "   ‚Ä¢ Websites: 18\n",
      "   ‚Ä¢ Facebook: 21\n",
      "   ‚Ä¢ Instagram: 20\n",
      "   ‚Ä¢ LinkedIn: 8\n",
      "   ‚Ä¢ TikTok: 0\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>Status</th>\n",
       "      <th>Error</th>\n",
       "      <th>Emails</th>\n",
       "      <th>Phones</th>\n",
       "      <th>Website</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>Instagram</th>\n",
       "      <th>TikTok</th>\n",
       "      <th>address</th>\n",
       "      <th>RecordOwl_Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T21LL0056H</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.creo.sg/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.instagram.com/creostudio.sg/]</td>\n",
       "      <td>None</td>\n",
       "      <td>101 LORONG 23 GEYLANG #08-01A PROSPER HOUSE 38...</td>\n",
       "      <td>https://recordowl.com/company/creo-design-llp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202344755W</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>[hello@boomglobalnetwork.com]</td>\n",
       "      <td>None</td>\n",
       "      <td>https://boomglobalnetwork.com/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>453B FERNVALE ROAD #08-513 FERNVALE FLORA 792453</td>\n",
       "      <td>https://recordowl.com/company/boom-global-priv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202232521M</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>[lstudio17@gmail.com]</td>\n",
       "      <td>[+6590688349]</td>\n",
       "      <td>https://www.lstudiodesign.net/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>18 SIMEI RISE #09-45 CHANGI RISE CONDOMINIUM 5...</td>\n",
       "      <td>https://recordowl.com/company/lstudio-design-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201938153M</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>[admin@triple3interior.com]</td>\n",
       "      <td>[+6588589225]</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.facebook.com/Triple3interior/]</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.instagram.com/triple3interior/?hl...</td>\n",
       "      <td>None</td>\n",
       "      <td>129 DESKER ROAD #02-01 SINGAPORE 209644</td>\n",
       "      <td>https://recordowl.com/company/triple-3-interio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202119084D</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>[contactus@architerior.sg]</td>\n",
       "      <td>[+6565233854]</td>\n",
       "      <td>https://thearchiinterior.com/</td>\n",
       "      <td>[https://www.facebook.com/architeriorsg/, http...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.instagram.com/architerior.sg/]</td>\n",
       "      <td>None</td>\n",
       "      <td>110 LORONG 23 GEYLANG #06-09 VICTORY CENTRE 38...</td>\n",
       "      <td>https://recordowl.com/company/architerior-pte-ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>202210283W</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.facebook.com/p/JSLim-Design-10009...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>281 BUKIT BATOK EAST AVENUE 3 #01-295 650281</td>\n",
       "      <td>https://recordowl.com/company/jslim-design-pte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202313773K</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>150 BISHAN STREET 11 #01-153 BISHAN GREEN 570150</td>\n",
       "      <td>https://recordowl.com/company/hoh-interior-des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202236194C</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://id-ea.com/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>6 UBI ROAD 1 #01-12 WINTECH CENTRE 408726</td>\n",
       "      <td>https://recordowl.com/company/id-ea-studio-pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>53465827W</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>443A BUKIT BATOK WEST AVENUE 8 #10-821 WEST RI...</td>\n",
       "      <td>https://recordowl.com/company/san-thong-interi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53381438C</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://donstudio.com/</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.linkedin.com/company/donstudio]</td>\n",
       "      <td>[https://www.instagram.com/studio.don/]</td>\n",
       "      <td>None</td>\n",
       "      <td>85 FLORA DRIVE #02-48 HEDGES PARK CONDOMINIUM ...</td>\n",
       "      <td>https://recordowl.com/company/don-studio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          UEN   Status Error                         Emails         Phones  \\\n",
       "0  T21LL0056H  success  None                           None           None   \n",
       "1  202344755W  success  None  [hello@boomglobalnetwork.com]           None   \n",
       "2  202232521M  success  None          [lstudio17@gmail.com]  [+6590688349]   \n",
       "3  201938153M  success  None    [admin@triple3interior.com]  [+6588589225]   \n",
       "4  202119084D  success  None     [contactus@architerior.sg]  [+6565233854]   \n",
       "5  202210283W  success  None                           None           None   \n",
       "6  202313773K  success  None                           None           None   \n",
       "7  202236194C  success  None                           None           None   \n",
       "8   53465827W  success  None                           None           None   \n",
       "9   53381438C  success  None                           None           None   \n",
       "\n",
       "                          Website  \\\n",
       "0            https://www.creo.sg/   \n",
       "1  https://boomglobalnetwork.com/   \n",
       "2  https://www.lstudiodesign.net/   \n",
       "3                            None   \n",
       "4   https://thearchiinterior.com/   \n",
       "5                            None   \n",
       "6                            None   \n",
       "7              https://id-ea.com/   \n",
       "8                            None   \n",
       "9          https://donstudio.com/   \n",
       "\n",
       "                                            Facebook  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3        [https://www.facebook.com/Triple3interior/]   \n",
       "4  [https://www.facebook.com/architeriorsg/, http...   \n",
       "5  [https://www.facebook.com/p/JSLim-Design-10009...   \n",
       "6                                               None   \n",
       "7                                               None   \n",
       "8                                               None   \n",
       "9                                               None   \n",
       "\n",
       "                                       LinkedIn  \\\n",
       "0                                          None   \n",
       "1                                          None   \n",
       "2                                          None   \n",
       "3                                          None   \n",
       "4                                          None   \n",
       "5                                          None   \n",
       "6                                          None   \n",
       "7                                          None   \n",
       "8                                          None   \n",
       "9  [https://www.linkedin.com/company/donstudio]   \n",
       "\n",
       "                                           Instagram TikTok  \\\n",
       "0         [https://www.instagram.com/creostudio.sg/]   None   \n",
       "1                                               None   None   \n",
       "2                                               None   None   \n",
       "3  [https://www.instagram.com/triple3interior/?hl...   None   \n",
       "4        [https://www.instagram.com/architerior.sg/]   None   \n",
       "5                                               None   None   \n",
       "6                                               None   None   \n",
       "7                                               None   None   \n",
       "8                                               None   None   \n",
       "9            [https://www.instagram.com/studio.don/]   None   \n",
       "\n",
       "                                             address  \\\n",
       "0  101 LORONG 23 GEYLANG #08-01A PROSPER HOUSE 38...   \n",
       "1   453B FERNVALE ROAD #08-513 FERNVALE FLORA 792453   \n",
       "2  18 SIMEI RISE #09-45 CHANGI RISE CONDOMINIUM 5...   \n",
       "3            129 DESKER ROAD #02-01 SINGAPORE 209644   \n",
       "4  110 LORONG 23 GEYLANG #06-09 VICTORY CENTRE 38...   \n",
       "5       281 BUKIT BATOK EAST AVENUE 3 #01-295 650281   \n",
       "6   150 BISHAN STREET 11 #01-153 BISHAN GREEN 570150   \n",
       "7          6 UBI ROAD 1 #01-12 WINTECH CENTRE 408726   \n",
       "8  443A BUKIT BATOK WEST AVENUE 8 #10-821 WEST RI...   \n",
       "9  85 FLORA DRIVE #02-48 HEDGES PARK CONDOMINIUM ...   \n",
       "\n",
       "                                      RecordOwl_Link  \n",
       "0      https://recordowl.com/company/creo-design-llp  \n",
       "1  https://recordowl.com/company/boom-global-priv...  \n",
       "2  https://recordowl.com/company/lstudio-design-p...  \n",
       "3  https://recordowl.com/company/triple-3-interio...  \n",
       "4  https://recordowl.com/company/architerior-pte-ltd  \n",
       "5  https://recordowl.com/company/jslim-design-pte...  \n",
       "6  https://recordowl.com/company/hoh-interior-des...  \n",
       "7  https://recordowl.com/company/id-ea-studio-pri...  \n",
       "8  https://recordowl.com/company/san-thong-interi...  \n",
       "9           https://recordowl.com/company/don-studio  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"‚úÖ SCRAPING COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"üìä Results Summary:\")\n",
    "print(f\"   ‚Ä¢ Total processed: {len(New_Fresh_Leads)}\")\n",
    "print(f\"   ‚Ä¢ Successful: {(New_Fresh_Leads['Status']=='success').sum()}\")\n",
    "print(f\"   ‚Ä¢ Failed: {(New_Fresh_Leads['Status']=='error').sum()}\")\n",
    "print(f\"   ‚Ä¢ Missing: {(New_Fresh_Leads['Status']=='missing').sum()}\")\n",
    "print(f\"\\nüìû Data Extracted:\")\n",
    "print(f\"   ‚Ä¢ Phones: {New_Fresh_Leads['Phones'].notna().sum()}\")\n",
    "print(f\"   ‚Ä¢ Emails: {New_Fresh_Leads['Emails'].notna().sum()}\")\n",
    "print(f\"   ‚Ä¢ Websites: {New_Fresh_Leads['Website'].notna().sum()}\")\n",
    "print(f\"   ‚Ä¢ Facebook: {New_Fresh_Leads['Facebook'].notna().sum()}\")\n",
    "print(f\"   ‚Ä¢ Instagram: {New_Fresh_Leads['Instagram'].notna().sum()}\")\n",
    "print(f\"   ‚Ä¢ LinkedIn: {New_Fresh_Leads['LinkedIn'].notna().sum()}\")\n",
    "print(f\"   ‚Ä¢ TikTok: {New_Fresh_Leads['TikTok'].notna().sum()}\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "New_Fresh_Leads.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd5c16f",
   "metadata": {},
   "source": [
    "### DIAGNOSTIC Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26931f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DIAGNOSTIC CODE - Run this to identify the issue\n",
    "# try:\n",
    "#     print(\"Testing Apify API connection...\")\n",
    "    \n",
    "#     # Test 1: Check if API key is valid\n",
    "#     user_info = client.user().get()\n",
    "#     print(f\"‚úÖ API Key valid - User: {user_info.get('username', 'Unknown')}\")\n",
    "    \n",
    "#     # Test 2: Check account limits and usage\n",
    "#     limits = user_info.get('limits', {})\n",
    "#     print(f\"\\nüìä Account Status:\")\n",
    "#     print(f\"   ‚Ä¢ Plan: {user_info.get('plan', 'Unknown')}\")\n",
    "#     print(f\"   ‚Ä¢ Credit balance: ${user_info.get('credit', 'N/A')}\")\n",
    "    \n",
    "#     # Test 3: Check if the actor exists\n",
    "#     try:\n",
    "#         actor_info = client.actor(\"apify/puppeteer-scraper\").get()\n",
    "#         print(f\"\\n‚úÖ Actor found: {actor_info.get('name', 'Unknown')}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"\\n‚ùå Actor not found: {e}\")\n",
    "    \n",
    "#     print(\"\\nüí° If you see JSONDecodeError above, most likely causes:\")\n",
    "#     print(\"   1. Out of Apify credits\")\n",
    "#     print(\"   2. Rate limit exceeded\")\n",
    "#     print(\"   3. Invalid API key\")\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(f\"‚ùå API Connection Failed: {type(e).__name__}: {e}\")\n",
    "#     print(\"\\nüí° Check:\")\n",
    "#     print(\"   1. Is your API key valid?\")\n",
    "#     print(\"   2. Do you have sufficient credits?\")\n",
    "#     print(\"   3. Is your network connection stable?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef4a99e",
   "metadata": {},
   "source": [
    "### Address Formatting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f7d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-compile patterns for speed\n",
    "POSTAL_RE = re.compile(r\"(?:\\bSingapore\\b\\s*)?(?P<postal>\\d{6})(?!\\d)\", re.IGNORECASE)\n",
    "UNIT_RES = [\n",
    "    re.compile(r\"#\\s*[A-Za-z0-9]{1,4}\\s*[-‚Äì]\\s*[A-Za-z0-9]{1,4}\", re.IGNORECASE),\n",
    "    re.compile(r\"\\bunit\\s*[#:]?\\s*[A-Za-z0-9]{1,4}\\s*[-‚Äì]\\s*[A-Za-z0-9]{1,4}\\b\", re.IGNORECASE),\n",
    "    re.compile(r\"\\bunit\\s*[#:]?\\s*[A-Za-z0-9]{1,5}\\b\", re.IGNORECASE),\n",
    "]\n",
    "\n",
    "def normalize_spaces(text: str) -> str:\n",
    "    text = re.sub(r\"[\\n\\r\\t]+\", \" \", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    return text.strip(\" ,;|/\")\n",
    "\n",
    "def extract_postal(text: str) -> tuple[str, str | None]:\n",
    "    if not text:\n",
    "        return text, None\n",
    "    matches = list(POSTAL_RE.finditer(text))\n",
    "    if matches:\n",
    "        m = matches[-1]\n",
    "        postal = m.group(\"postal\")\n",
    "        start, end = m.span()\n",
    "        cleaned = text[:start] + text[end:]\n",
    "        cleaned = re.sub(r\"\\bSingapore\\b\", \"\", cleaned, flags=re.IGNORECASE)\n",
    "        return normalize_spaces(cleaned), postal\n",
    "    return normalize_spaces(text), None\n",
    "\n",
    "def extract_unit(text: str) -> tuple[str, str | None]:\n",
    "    if not text:\n",
    "        return text, None\n",
    "    for rx in UNIT_RES:\n",
    "        m = rx.search(text)\n",
    "        if m:\n",
    "            unit_raw = m.group(0)\n",
    "            cleaned = normalize_spaces(text[:m.start()] + text[m.end():])\n",
    "            unit_digits = re.sub(r\"^unit\\s*[#:]?\\s*\", \"\", unit_raw, flags=re.IGNORECASE)\n",
    "            unit_digits = normalize_spaces(unit_digits)\n",
    "            unit_digits = unit_digits.replace(' ‚Äì ', '-').replace('‚Äì', '-').replace(' ', '')\n",
    "            unit_digits = unit_digits.lstrip('#')\n",
    "            return cleaned, unit_digits\n",
    "    return normalize_spaces(text), None\n",
    "\n",
    "def clean_street(text: str) -> str | None:\n",
    "    if not text:\n",
    "        return None\n",
    "    text = normalize_spaces(text)\n",
    "    text = re.sub(r\"\\s*,\\s*\", \", \", text)\n",
    "    return text if text.isupper() else text.title()\n",
    "\n",
    "def split_address_sg(address: str) -> dict:\n",
    "    if not isinstance(address, str) or not address.strip():\n",
    "        return {\"street\": None, \"unit\": None, \"postal_code\": None, \"address_clean\": None}\n",
    "    raw = normalize_spaces(address)\n",
    "    without_postal, postal = extract_postal(raw)\n",
    "    without_unit, unit = extract_unit(without_postal)\n",
    "    without_unit = normalize_spaces(re.sub(r\"\\bSingapore\\b\", \"\", without_unit, flags=re.IGNORECASE))\n",
    "    street = clean_street(without_unit)\n",
    "    address_clean = normalize_spaces(\" \".join(x for x in [street or \"\", unit or \"\", f\"Singapore {postal}\" if postal else \"\"] if x))\n",
    "    return {\"street\": street, \"unit\": unit, \"postal_code\": postal, \"address_clean\": address_clean}\n",
    "\n",
    "# Apply to current result DF -> create a new dataframe with clean components\n",
    "if 'address' not in New_Fresh_Leads.columns:\n",
    "    raise ValueError(\"Column 'address' not found in New_Fresh_Leads. Run the scraping cell first.\")\n",
    "\n",
    "parsed_df = pd.DataFrame(list(New_Fresh_Leads[\"address\"].apply(split_address_sg)))\n",
    "\n",
    "# New DataFrame with clean address fields and without raw 'address'\n",
    "Cleaned_New_Fresh_Leads = New_Fresh_Leads.copy()\n",
    "if 'address' in Cleaned_New_Fresh_Leads.columns:\n",
    "    Cleaned_New_Fresh_Leads = Cleaned_New_Fresh_Leads.drop(columns=['address'])\n",
    "Cleaned_New_Fresh_Leads[\"operational_street\"] = parsed_df[\"street\"]\n",
    "Cleaned_New_Fresh_Leads[\"operational_unit\"] = parsed_df[\"unit\"]\n",
    "Cleaned_New_Fresh_Leads[\"operational_postal_code\"] = parsed_df[\"postal_code\"]\n",
    "Cleaned_New_Fresh_Leads[\"operational_address\"] = parsed_df[\"address_clean\"]\n",
    "\n",
    "# Save full result to a new DataFrame and display all columns\n",
    "New_Fresh_Leads_Operational = Cleaned_New_Fresh_Leads.copy()\n",
    "New_Fresh_Leads_Operational"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad65e275",
   "metadata": {},
   "source": [
    "### Check for duplication of UEN and Phone Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22aefd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean masks for duplicates\n",
    "uen_dup = New_Fresh_Leads_Operational[\"UEN\"].duplicated(keep=False)\n",
    "\n",
    "phone_dup = (\n",
    "    New_Fresh_Leads_Operational[\"Phones\"].notna() &\n",
    "    New_Fresh_Leads_Operational[\"Phones\"].duplicated(keep=False)\n",
    ")\n",
    "\n",
    "# YES/NO summary\n",
    "print(\n",
    "    \"UEN dup:\", \"YES\" if uen_dup.any() else \"NO\",\n",
    "    \"| Phone dup:\", \"YES\" if phone_dup.any() else \"NO\"\n",
    ")\n",
    "\n",
    "# Show duplicate rows if exist\n",
    "if uen_dup.any():\n",
    "    print(\"\\nüîÅ Duplicate UEN rows:\")\n",
    "    display(New_Fresh_Leads_Operational[uen_dup])\n",
    "\n",
    "if phone_dup.any():\n",
    "    print(\"\\nüì± Duplicate Phone rows:\")\n",
    "    display(New_Fresh_Leads_Operational[phone_dup])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7bc1c8",
   "metadata": {},
   "source": [
    "### Drop duplicate phone numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dbd816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert list-like Phones into strings for comparison\n",
    "# New_Fresh_Leads_Operational[\"Phones_str\"] = (\n",
    "#     New_Fresh_Leads_Operational[\"Phones\"].astype(str)\n",
    "# )\n",
    "\n",
    "# # Create a NEW DataFrame with duplicate phone numbers removed\n",
    "# New_Fresh_Leads_Operational_unique_phones = (\n",
    "#     New_Fresh_Leads_Operational.drop_duplicates(\n",
    "#         subset=\"Phones_str\", keep=\"first\"\n",
    "#     )\n",
    "#     .drop(columns=[\"Phones_str\"])  # clean up helper column\n",
    "# )\n",
    "\n",
    "# # Show size change\n",
    "# print(\"Original:\", len(New_Fresh_Leads_Operational))\n",
    "# print(\"Unique Phones:\", len(New_Fresh_Leads_Operational_unique_phones))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbe5fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "New_Fresh_Leads_Operational_x = New_Fresh_Leads_Operational.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54663ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "New_Fresh_Leads_Operational_x.to_parquet(\"./Staging/Silver/Silver_data_2_500_2.parquet\", index=False, engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d354f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New_Fresh_Leads_Operational.to_csv(\"New_Fresh_Leads_Operational.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
